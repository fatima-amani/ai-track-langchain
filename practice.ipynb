{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.3.35)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.3.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (3.11.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fatima\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatima\\AppData\\Local\\Temp\\ipykernel_22052\\242832224.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"phi3\")\n",
      "C:\\Users\\Fatima\\AppData\\Local\\Temp\\ipykernel_22052\\242832224.py:4: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm.predict(\"Tell me a programming joke\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the computer cold? Because it left its Windows open!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"phi3\")\n",
    "response = llm.predict(\"Tell me a programming joke\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "# ! pip install langchain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Explain {topic} in simple terms\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt = template.format(topic=\"Langchain\")\n",
    "chain = llm | prompt\n",
    "# print(prompt)\n",
    "output = chain.run(\"Langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_ollama\n",
    "# ! pip install langchain_core\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = \"\"\"\" Explain {topic} in simple words \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=prompt, input_variables=[\"topic\"])\n",
    "chain = llm | prompt_template\n",
    "\n",
    "while True:\n",
    "    topic = input(\"User: Explain me about: \")\n",
    "    if topic.lower() == 'exit':\n",
    "        break\n",
    "    output = chain.invoke({\"topic\":topic})\n",
    "    print(f\"Bot:{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:text=' Explain this Here is a simple Python greeting script:\\n\\n```python\\nprint(\"Hello, world!\")\\n```\\n\\nWhen run, this code will output the following text to the console:\\n\\n```\\nHello, world!\\n```\\n'\n",
      "Bot:text=' Explain this To demonstrate a simple Python script that prints \"Hello, World!\", here is an example:\\n\\n```python\\nprint(\"Hello, World!\")\\n```\\n\\nWhen you run this code in any environment where Python is installed (e.g., command line interface), it will output the following to your screen:\\n\\n```\\nHello, World!\\n```\\n'\n",
      "Bot:text=' Explain this \"Hello, Gen AI. How can I assist you today?\" or \"Greetings to all users interacting with me! Remember that while artificial intelligence has a wealth of knowledge at its disposal, it\\'selff is not sentient and does not possess personal experiences or emotions.\"\\n'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m chain \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;241m|\u001b[39m prompt_template\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: Explain to me about: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m topic\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m topic\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1270\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1313\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = OllamaLLM(model=\"phi3\")\n",
    "\n",
    "prompt = \"\"\" Explain this {topic}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(template=prompt, input_variables=[\"topic\"])\n",
    "chain = llm | prompt_template\n",
    "\n",
    "while True:\n",
    "    topic = input(\"User: Explain to me about: \")\n",
    "    if topic.lower() == \"exit\" or topic.lower() == \"quit\":\n",
    "        break\n",
    "    output = chain.invoke(topic)\n",
    "    print(f\"Bot:{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:To execute the command 'cat' in a Linux environment, you would open your terminal and simply type:\n",
      "\n",
      "```bash\n",
      "cat filename.txt\n",
      "```\n",
      "\n",
      "This will display the contents of `filename.txt` to your screen if it exists or prompts an error message if not found within the current directory.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = OllamaLLM(model=\"phi3\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    topic = input(\"User: Explain to me about: \")\n",
    "    if topic.lower() == \"exit\" or topic.lower() == \"quit\":\n",
    "        break\n",
    "    output = llm.predict(topic)\n",
    "    print(f\"Bot:{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
